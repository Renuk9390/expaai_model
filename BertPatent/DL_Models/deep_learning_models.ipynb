{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop\n",
    "from keras.layers import Embedding,Dense,Dropout,GRU, LSTM\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Scaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thereby, the return oil is prevented from goin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>', 'While the present inventors examined impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For example, the inner core portion and the ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In a case where the traffic amount is small, w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>', 'In the twelfth aspect of the invention, ac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Thereby, the return oil is prevented from goin...       1\n",
       "1  ', 'While the present inventors examined impro...       0\n",
       "2  For example, the inner core portion and the ou...       0\n",
       "3  In a case where the traffic amount is small, w...       2\n",
       "4  ', 'In the twelfth aspect of the invention, ac...       0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = pd.read_csv('../../tmp/sentence_based_data_300K.csv')\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = combined[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = combined.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=100000)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences, maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 512)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,y_cat,test_size=0.2,random_state=101)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size=0.5,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n",
      "30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_FILE = 'C:/Study/glove.6B.100d.txt'\n",
    "f = open(GLOVE_FILE,'r',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "import numpy as np\n",
    "for line in f:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  embeddings_index[word] = np.asarray(values[1:], dtype='float32')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, 100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         5669600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               117248    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,814,275\n",
      "Trainable params: 144,675\n",
      "Non-trainable params: 5,669,600\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(word_index)+1, 100, weights=[embedding_matrix],trainable=False))\n",
    "\n",
    "model.add(LSTM(units=128,dropout = 0.5,recurrent_dropout = 0.2))\n",
    "\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "# output model skeleton\n",
    "opt = Adam(learning_rate = 0.005)\n",
    "model.summary()\n",
    "model.compile(optimizer= opt , loss ='categorical_crossentropy',metrics=['accuracy'])\n",
    "plot_model(model, to_file='/content/drive/MyDrive/dataset_patent/figures/dl_model_anno_50.png', show_shapes=True, show_layer_names=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "7500/7500 [==============================] - 9425s 1s/step - loss: 0.9344 - accuracy: 0.5448\n",
      "Epoch 2/2\n",
      "7500/7500 [==============================] - 9410s 1s/step - loss: 0.8037 - accuracy: 0.6568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b5c3bd8d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, verbose=1, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 68s 72ms/step - loss: 0.7037 - accuracy: 0.7117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7037455439567566, 0.7116666436195374]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 69s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 3)\n",
      "(30000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.67      9993\n",
      "           1       0.79      0.53      0.63     10051\n",
      "           2       0.84      0.62      0.71      9956\n",
      "\n",
      "   micro avg       0.80      0.58      0.67     30000\n",
      "   macro avg       0.80      0.58      0.67     30000\n",
      "weighted avg       0.80      0.58      0.67     30000\n",
      " samples avg       0.58      0.58      0.58     30000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ranax\\anaconda3\\envs\\bert_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print((classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential model LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without using glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56695"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 512, 100)          5669600   \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                42240     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,712,035\n",
      "Trainable params: 5,712,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "# model1.add(Embedding(len(word_index)+1, 100, weights=[embedding_matrix]))\n",
    "model1.add(layers.Embedding(len(word_index)+1, 100, input_length=max_len))\n",
    "# model1.add(Embedding(max_words, 20))\n",
    "model1.add(LSTM(64,dropout=0.5))\n",
    "model1.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model1.summary()\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "# checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "plot_model(model1, to_file='dl_model_lstm_wo_anno_400.png', show_shapes=True, show_layer_names=True, dpi=400)\n",
    "plot_model(model1, to_file='dl_model_lstm_wo_anno_50.png', show_shapes=True, show_layer_names=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7500/7500 [==============================] - 1300s 173ms/step - loss: 0.6117 - accuracy: 0.7512 - val_loss: 0.5374 - val_accuracy: 0.7853\n",
      "Epoch 2/10\n",
      "7500/7500 [==============================] - 1321s 176ms/step - loss: 0.5229 - accuracy: 0.7914 - val_loss: 0.5047 - val_accuracy: 0.8011\n",
      "Epoch 3/10\n",
      "7500/7500 [==============================] - 1344s 179ms/step - loss: 0.4921 - accuracy: 0.8056 - val_loss: 0.4868 - val_accuracy: 0.8089\n",
      "Epoch 4/10\n",
      "7500/7500 [==============================] - 1362s 182ms/step - loss: 0.4719 - accuracy: 0.8153 - val_loss: 0.4776 - val_accuracy: 0.8105\n",
      "Epoch 5/10\n",
      "7500/7500 [==============================] - 1357s 181ms/step - loss: 0.4565 - accuracy: 0.8233 - val_loss: 0.4710 - val_accuracy: 0.8139\n",
      "Epoch 6/10\n",
      "7500/7500 [==============================] - 1383s 184ms/step - loss: 0.4463 - accuracy: 0.8272 - val_loss: 0.4702 - val_accuracy: 0.8169\n",
      "Epoch 7/10\n",
      "7500/7500 [==============================] - 1414s 189ms/step - loss: 0.4396 - accuracy: 0.8298 - val_loss: 0.4713 - val_accuracy: 0.8187\n",
      "Epoch 8/10\n",
      "7500/7500 [==============================] - 1419s 189ms/step - loss: 0.4344 - accuracy: 0.8317 - val_loss: 0.4692 - val_accuracy: 0.8164\n",
      "Epoch 9/10\n",
      "7500/7500 [==============================] - 1426s 190ms/step - loss: 0.4299 - accuracy: 0.8346 - val_loss: 0.4636 - val_accuracy: 0.8189\n",
      "Epoch 10/10\n",
      "7500/7500 [==============================] - 1443s 192ms/step - loss: 0.4261 - accuracy: 0.8361 - val_loss: 0.4624 - val_accuracy: 0.8186\n"
     ]
    }
   ],
   "source": [
    "# history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])\n",
    "history_1 = model1.fit(X_train, y_train, validation_data=(X_val, y_val), verbose=1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Study\\Master Thesis\\expaai_model\\BertPatent\\DL_Models\\deep_learning_models.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Study/Master%20Thesis/expaai_model/BertPatent/DL_Models/deep_learning_models.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(history_1\u001b[39m.\u001b[39mhistory[\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history_1' is not defined"
     ]
    }
   ],
   "source": [
    "a = len(history_1.history[\"loss\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('bert_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4655d434983e15677638913597445993328257199604ecd9512c80288112199c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

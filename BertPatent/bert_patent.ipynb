{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv(\"C:/Study/Master Thesis/expaai_model/tmp/cleaned_data_150k.csv\") \n",
    "data.columns = ['text', 'label']\n",
    "\n",
    "# data.head()\n",
    "\n",
    "data.to_csv('../tmp/cleaned_data_with_labels_150k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d6609920110419df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\ranax\\.cache\\huggingface\\datasets\\csv\\default-d6609920110419df\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5df889f9f246e394fc396d377f2532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75a5edc025e470e82c2cee37a0d0abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce45f27a885b4edaa835219608710593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\ranax\\.cache\\huggingface\\datasets\\csv\\default-d6609920110419df\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4485478919488f8873c84b6e3a0469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "paragraph_data = load_dataset(\"csv\", data_files=\"C:/Study/Master Thesis/expaai_model/tmp/cleaned_data_with_labels_150k.csv\")\n",
    "# paragraph_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\ranax\\.cache\\huggingface\\datasets\\csv\\default-d6609920110419df\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-7619a88dcc424e83.arrow\n"
     ]
    }
   ],
   "source": [
    "paragraph_data_randomized = paragraph_data[\"train\"].shuffle(seed=42)\n",
    "paragraph_data_randomized_rows = paragraph_data.num_rows['train']\n",
    "train_end = round(paragraph_data_randomized_rows * 0.67)\n",
    "\n",
    "paragraph_train_dataset = paragraph_data_randomized.select([i for i in list(range(train_end))])\n",
    "paragraph_test_dataset = paragraph_data_randomized.select([i for i in list(range(train_end, paragraph_data_randomized_rows))])\n",
    "\n",
    "#paragraph_train_dataset\n",
    "#paragraph_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraph_train_dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/anferico/bert-for-patents/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ad9665ebfb3752215321190b40835afc46da469265b8bd17501173eb6f7ad8c0.607ba830f1d59bcf5505774afff2deee461950e07e7e50c9e3d4595f91401ba0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"anferico/bert-for-patents\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/anferico/bert-for-patents/resolve/main/vocab.txt from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\b13030055afe1092c977effef2b4b69b1cd2e7c95d9eb334dbea9cea04a5fb7f.9c89dc140f6b66fc35139caa1816f2b0deb4c000d58afc2dc668f74dae394d2d\n",
      "loading file https://huggingface.co/anferico/bert-for-patents/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/anferico/bert-for-patents/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/anferico/bert-for-patents/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/anferico/bert-for-patents/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/anferico/bert-for-patents/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ad9665ebfb3752215321190b40835afc46da469265b8bd17501173eb6f7ad8c0.607ba830f1d59bcf5505774afff2deee461950e07e7e50c9e3d4595f91401ba0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"anferico/bert-for-patents\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/anferico/bert-for-patents/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ad9665ebfb3752215321190b40835afc46da469265b8bd17501173eb6f7ad8c0.607ba830f1d59bcf5505774afff2deee461950e07e7e50c9e3d4595f91401ba0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"anferico/bert-for-patents\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"anferico/bert-for-patents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\ranax\\.cache\\huggingface\\datasets\\csv\\default-d6609920110419df\\0.0.0\\652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a\\cache-adb5e3442e064574.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb66d6747034037ba38caa5ad969355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=True,max_length=50, add_special_tokens = True)\n",
    "\n",
    "tokenized_train = paragraph_train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_test = paragraph_test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'According to the organic EL display panel and the method for manufacturing the same of the present invention can make a film shape of the organic functional layer of the light emitting element at an edge of the effective emission region favorable. In addition, it is possible to reduce the number of the contact holes and the holes formed in the planarized film and to thereby make the surface area of the planarized film as small as possible. Therefore, it is possible to further suppress absorption of moisture in the planarized film and diffusion of moisture from the planarized film into other layers. For this reason, the organic EL display panel of the present invention can achieve small luminance unevenness and emission color unevenness and high display quality, and can further suppress deterioration in emission characteristics.',\n",
       " 'label': 1,\n",
       " 'input_ids': [2,\n",
       "  2094,\n",
       "  1665,\n",
       "  1661,\n",
       "  7219,\n",
       "  3114,\n",
       "  4318,\n",
       "  5662,\n",
       "  1663,\n",
       "  1661,\n",
       "  3783,\n",
       "  1670,\n",
       "  5479,\n",
       "  1661,\n",
       "  1833,\n",
       "  1662,\n",
       "  1661,\n",
       "  2221,\n",
       "  10693,\n",
       "  1729,\n",
       "  1856,\n",
       "  1042,\n",
       "  1808,\n",
       "  4003,\n",
       "  1662,\n",
       "  1661,\n",
       "  7219,\n",
       "  8025,\n",
       "  6406,\n",
       "  1662,\n",
       "  1661,\n",
       "  2087,\n",
       "  29872,\n",
       "  5448,\n",
       "  1677,\n",
       "  1684,\n",
       "  3006,\n",
       "  1662,\n",
       "  1661,\n",
       "  4286,\n",
       "  15425,\n",
       "  2220,\n",
       "  10784,\n",
       "  1017,\n",
       "  1664,\n",
       "  2469,\n",
       "  1015,\n",
       "  1674,\n",
       "  1668,\n",
       "  3],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/anferico/bert-for-patents/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ad9665ebfb3752215321190b40835afc46da469265b8bd17501173eb6f7ad8c0.607ba830f1d59bcf5505774afff2deee461950e07e7e50c9e3d4595f91401ba0\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"anferico/bert-for-patents\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/anferico/bert-for-patents/resolve/main/pytorch_model.bin from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\40a89203145e35613eae7d0613652c2e35fbd93554d9ee210216e92c724ba10c.22137c023d726523dbedff2b9657af89735d081f405c9c670cce8c60ba39da5d\n",
      "Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at anferico/bert-for-patents and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"anferico/bert-for-patents\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    load_accuracy = load_metric(\"accuracy\")\n",
    "    load_f1 = load_metric(\"f1\")\n",
    "    \n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    f1 = load_f1.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 0.5}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load_accuracy = load_metric(\"accuracy\")\n",
    "# load_accuracy.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0])\n",
    "\n",
    "load_f1 = load_metric(\"f1\")\n",
    "load_f1.compute(references=[0, 1, 2, 0, 1, 2], predictions=[0, 1, 1, 2, 1, 0], average=\"micro\")\n",
    "\n",
    "# from datasets import list_metrics\n",
    "# list_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to C:\\Users\\ranax/.huggingface/token\n",
      "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
      "\n",
      "git config --global credential.helper store\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "c:\\Study\\Master Thesis\\expaai_model\\BertPatent\\bert-for-patent is already a clone of https://huggingface.co/fassahat/bert-for-patent. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "# Define a new Trainer with all the objects we constructed so far\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "repo_name = \"bert-for-patent\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\", \n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 49500\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4582ea72414d54b12bbfc3db3747a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2239919900894165,\n",
       " 'eval_accuracy': 0.3336767676767677,\n",
       " 'eval_f1': 0.3336767676767677,\n",
       " 'eval_runtime': 1847.1688,\n",
       " 'eval_samples_per_second': 26.798,\n",
       " 'eval_steps_per_second': 1.675}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to bert-for-patent\n",
      "Configuration saved in bert-for-patent\\config.json\n",
      "Model weights saved in bert-for-patent\\pytorch_model.bin\n",
      "tokenizer config file saved in bert-for-patent\\tokenizer_config.json\n",
      "Special tokens file saved in bert-for-patent\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f220db74ec491e809c75ada38cfdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/1.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76990512808a4ffbbb0e69652944b515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file training_args.bin: 100%|##########| 3.23k/3.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/fassahat/bert-for-patent\n",
      "   12a147c..5e7a0fa  main -> main\n",
      "\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Text Classification', 'type': 'text-classification'}}\n",
      "To https://huggingface.co/fassahat/bert-for-patent\n",
      "   5e7a0fa..c17c321  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fassahat/bert-for-patent/commit/5e7a0fa3c1c39f9745995132e92beef18bcfa05f'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/config.json not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmpjm1f2o0f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89cddf4b91a486bbab1b1f8b8b7dafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/config.json in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\805662ad68bc5873735c511c6d9ae90801f2bc14d9c22acf62ec5dd96eecc962.c530123a1af49ed0d4a7d7d6ec7c7cc0e9e385346735a75aa51aa6768a2bd9ae\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\805662ad68bc5873735c511c6d9ae90801f2bc14d9c22acf62ec5dd96eecc962.c530123a1af49ed0d4a7d7d6ec7c7cc0e9e385346735a75aa51aa6768a2bd9ae\n",
      "loading configuration file https://huggingface.co/fassahat/bert-for-patent/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\805662ad68bc5873735c511c6d9ae90801f2bc14d9c22acf62ec5dd96eecc962.c530123a1af49ed0d4a7d7d6ec7c7cc0e9e385346735a75aa51aa6768a2bd9ae\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"fassahat/bert-for-patent\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac464e6d53bd40c78dad98261574d63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/fassahat/bert-for-patent/resolve/main/config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\805662ad68bc5873735c511c6d9ae90801f2bc14d9c22acf62ec5dd96eecc962.c530123a1af49ed0d4a7d7d6ec7c7cc0e9e385346735a75aa51aa6768a2bd9ae\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"fassahat/bert-for-patent\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 39859\n",
      "}\n",
      "\n",
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmpisndpj_8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92075f9141244b73af5c3b15854ecb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/pytorch_model.bin in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\4a9afff6de7545db1ef56fb4ecace0a47cc44705dda20f10c0bd64f509fea7cd.0ef7cb179a37032843c28b2c55b8ba7d312d6e44596aa433a59a40fc8abb8f72\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\4a9afff6de7545db1ef56fb4ecace0a47cc44705dda20f10c0bd64f509fea7cd.0ef7cb179a37032843c28b2c55b8ba7d312d6e44596aa433a59a40fc8abb8f72\n",
      "loading weights file https://huggingface.co/fassahat/bert-for-patent/resolve/main/pytorch_model.bin from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\4a9afff6de7545db1ef56fb4ecace0a47cc44705dda20f10c0bd64f509fea7cd.0ef7cb179a37032843c28b2c55b8ba7d312d6e44596aa433a59a40fc8abb8f72\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at fassahat/bert-for-patent.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmpnju_o2hk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623a894633134bc48d97f81ed0c4fb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/381 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer_config.json in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ea3b3138af3bb2c22a1be9161920935f5b78230ff4a283fc6730acfd35a234ba.b527309dec4079e835b6e29ac399f3cd3ab700485e68976a484dac3ce6ae3911\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\ea3b3138af3bb2c22a1be9161920935f5b78230ff4a283fc6730acfd35a234ba.b527309dec4079e835b6e29ac399f3cd3ab700485e68976a484dac3ce6ae3911\n",
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmpwswdihet\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ee8924ca22427fb749ba84346b5a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/322k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/vocab.txt in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\37941dec739f471f7ccf28be895d475747ea413a9546daade523fb634dadd4dd.cd71be873e111a6c22b39ab6bcbd9396a088a052b409986b5f2e5c913a024d6e\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\37941dec739f471f7ccf28be895d475747ea413a9546daade523fb634dadd4dd.cd71be873e111a6c22b39ab6bcbd9396a088a052b409986b5f2e5c913a024d6e\n",
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmplt_w21k2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278c69ede24241f5b40e36e538aab9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/936k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer.json in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\703db49331ef6263cb6756592822649b06687da0232198b3eed7160f3f303d2b.f94e214638d9f00caff260dbbac9bbaf1641ea9e8968cfa305d4b360493b2111\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\703db49331ef6263cb6756592822649b06687da0232198b3eed7160f3f303d2b.f94e214638d9f00caff260dbbac9bbaf1641ea9e8968cfa305d4b360493b2111\n",
      "https://huggingface.co/fassahat/bert-for-patent/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to C:\\Users\\ranax\\.cache\\huggingface\\transformers\\tmpncyicvpz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8451375cc7d346199a3620eb16fe2943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/fassahat/bert-for-patent/resolve/main/special_tokens_map.json in cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\37bd2a4ae533dc19cc7e45201c3175c1061a410bf7e0839358641e32d0c4ea8f.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
      "creating metadata file for C:\\Users\\ranax/.cache\\huggingface\\transformers\\37bd2a4ae533dc19cc7e45201c3175c1061a410bf7e0839358641e32d0c4ea8f.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
      "loading file https://huggingface.co/fassahat/bert-for-patent/resolve/main/vocab.txt from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\37941dec739f471f7ccf28be895d475747ea413a9546daade523fb634dadd4dd.cd71be873e111a6c22b39ab6bcbd9396a088a052b409986b5f2e5c913a024d6e\n",
      "loading file https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\703db49331ef6263cb6756592822649b06687da0232198b3eed7160f3f303d2b.f94e214638d9f00caff260dbbac9bbaf1641ea9e8968cfa305d4b360493b2111\n",
      "loading file https://huggingface.co/fassahat/bert-for-patent/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/fassahat/bert-for-patent/resolve/main/special_tokens_map.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\37bd2a4ae533dc19cc7e45201c3175c1061a410bf7e0839358641e32d0c4ea8f.7da70648c6cb9951e284c9685f9ba7ae083dd59ed1d6d84bdfc0584a4ea94b6d\n",
      "loading file https://huggingface.co/fassahat/bert-for-patent/resolve/main/tokenizer_config.json from cache at C:\\Users\\ranax/.cache\\huggingface\\transformers\\ea3b3138af3bb2c22a1be9161920935f5b78230ff4a283fc6730acfd35a234ba.b527309dec4079e835b6e29ac399f3cd3ab700485e68976a484dac3ce6ae3911\n",
      "Disabling tokenizer parallelism, we're using DataLoader multithreading already\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.38417473435401917}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    " \n",
    "bert_patent_model = pipeline(model=\"fassahat/bert-for-patent\")\n",
    "bert_patent_model([\"', 'The vibrator may be pressed with a pressing force in the range from 3N to 10N.\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('bert_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4655d434983e15677638913597445993328257199604ecd9512c80288112199c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
